{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xq_u5mj7L8Av"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from preprocessing import extract_data_mooc, extractFeatures,extractItemUserId,extractNextStateItem,extractNextUserState,UserNextInteraction, delta, t_batch_update,train_test_split,train_test_stratified_split\n",
        "from model import RODIE,dynamic_embedding\n",
        "from sklearn.manifold import TSNE\n",
        "from train import train_rodie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2fs_9WWL8Ax",
        "outputId": "39d4e923-5733-4f68-b365-de002795bb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-17 10:41:00--  https://snap.stanford.edu/data/act-mooc.tar.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5378133 (5.1M) [application/x-gzip]\n",
            "Saving to: ‘act-mooc.tar.gz’\n",
            "\n",
            "act-mooc.tar.gz     100%[===================>]   5.13M  4.89MB/s    in 1.0s    \n",
            "\n",
            "2022-03-17 10:41:01 (4.89 MB/s) - ‘act-mooc.tar.gz’ saved [5378133/5378133]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Téléchargement des données\n",
        "!wget https://snap.stanford.edu/data/act-mooc.tar.gz\n",
        "!tar -xzf  act-mooc.tar.gz\n",
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4T5CbB9KL8Ax"
      },
      "outputs": [],
      "source": [
        "features = pd.read_csv(\"act-mooc/mooc_action_features.tsv\",sep=\"\\t\")\n",
        "labels = pd.read_csv(\"act-mooc/mooc_action_labels.tsv\",sep=\"\\t\")\n",
        "users = pd.read_csv(\"act-mooc/mooc_actions.tsv\",sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLCAaTlZL8Ay"
      },
      "source": [
        "#### Load & Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "nFoGBgxNL8Az",
        "outputId": "658a6d29-3330-42d7-9eaa-5a3836976303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta user_id\n",
            "delta item_id\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          user_id  item_id  timestamp  state_label  delta_u  delta_i  \\\n",
              "ACTIONID                                                               \n",
              "0               0        0        0.0            0        0        0   \n",
              "1               0        1        6.0            0        6        0   \n",
              "2               0        2       41.0            0       35        0   \n",
              "3               0        1       49.0            0        8       43   \n",
              "4               0        2       51.0            0        2       10   \n",
              "\n",
              "          nextItemInteraction  next_state_user        f1        f2        f3  \\\n",
              "ACTIONID                                                                       \n",
              "0                           1                0 -0.319991 -0.435701  0.106784   \n",
              "1                           2                0 -0.319991 -0.435701  0.106784   \n",
              "2                           1                0 -0.319991 -0.435701  0.106784   \n",
              "3                           2                0 -0.319991 -0.435701  0.106784   \n",
              "4                           3                0 -0.319991 -0.435701  0.106784   \n",
              "\n",
              "                f4  \n",
              "ACTIONID            \n",
              "0        -0.067309  \n",
              "1        -0.067309  \n",
              "2        -0.067309  \n",
              "3        -0.067309  \n",
              "4        -0.067309  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06ef258e-e12c-44e8-9bba-d3112e664bd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>state_label</th>\n",
              "      <th>delta_u</th>\n",
              "      <th>delta_i</th>\n",
              "      <th>nextItemInteraction</th>\n",
              "      <th>next_state_user</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACTIONID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.319991</td>\n",
              "      <td>-0.435701</td>\n",
              "      <td>0.106784</td>\n",
              "      <td>-0.067309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.319991</td>\n",
              "      <td>-0.435701</td>\n",
              "      <td>0.106784</td>\n",
              "      <td>-0.067309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.319991</td>\n",
              "      <td>-0.435701</td>\n",
              "      <td>0.106784</td>\n",
              "      <td>-0.067309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.319991</td>\n",
              "      <td>-0.435701</td>\n",
              "      <td>0.106784</td>\n",
              "      <td>-0.067309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.319991</td>\n",
              "      <td>-0.435701</td>\n",
              "      <td>0.106784</td>\n",
              "      <td>-0.067309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06ef258e-e12c-44e8-9bba-d3112e664bd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06ef258e-e12c-44e8-9bba-d3112e664bd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06ef258e-e12c-44e8-9bba-d3112e664bd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mooc_data = extract_data_mooc()\n",
        "\n",
        "delta_u  = delta(mooc_data.copy(),\"user_id\")\n",
        "delta_i  = delta(mooc_data.copy(),\"item_id\")\n",
        "nextItemInteraction = UserNextInteraction(mooc_data.copy())\n",
        "next_state_user = extractNextUserState(mooc_data.copy())\n",
        "\n",
        "\n",
        "mooc_data['delta_u'] = delta_u\n",
        "mooc_data['delta_i'] = delta_i\n",
        "mooc_data['nextItemInteraction'] = nextItemInteraction\n",
        "mooc_data['next_state_user'] = next_state_user\n",
        "\n",
        "data = mooc_data.copy()\n",
        "data = data[ (data.nextItemInteraction != -1) | (data.next_state_user != -1)  ]\n",
        "\n",
        "data = data[['user_id', 'item_id', 'timestamp', 'state_label','delta_u', 'delta_i', 'nextItemInteraction', 'next_state_user','f1', 'f2', 'f3','f4']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiCCdNMNL8A0"
      },
      "source": [
        "### T-batches\n",
        "\n",
        "#### Train / Test SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train1,df_test1 = train_test_stratified_split(data)\n",
        "df_train2,df_test2 = train_test_stratified_split(df_test1)\n",
        "df_train3,df_test = train_test_stratified_split(df_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wie0TKqkWHVE",
        "outputId": "b7d77e92-7605-40ef-eba6-81023b114f32"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
            "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
            "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train1],axis=0)\n",
        "df_train.shape,df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky7PRw8iWP7R",
        "outputId": "bfb9519e-178a-4449-defc-62919d9c2f2b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((202351, 12), (50587, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Proportion of dropout user in :\\n Train data = {:.1f}%\\n Test Data= {:.1f}%\".format(100*np.sum(df_train['next_state_user'])/df_train.shape[0],100*np.sum(df_test['next_state_user'])/df_test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK28dwsxXA8J",
        "outputId": "bbdd5184-9048-4584-9311-b223d4bf85ac"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of dropout user in :\n",
            " Train data = 1.0%\n",
            " Test Data= 1.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_batches_train = t_batch_update(df_train)\n",
        "t_batches_test = t_batch_update(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4-z_QuOQfk4",
        "outputId": "77a50f87-78aa-4dc7-9026-bf1887a23824"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-Batch start...\n",
            "Number of interaction = 202351\n",
            "T-Batch ends !\n",
            "T-Batch start...\n",
            "Number of interaction = 50587\n",
            "T-Batch ends !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZldOSzFL8A1"
      },
      "source": [
        "##### Initialize Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xuMzz5NL8A1",
        "outputId": "6d045423-9681-4ae9-a2c0-b9774566da7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = \"cpu\"\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyoLG1SXL8A2"
      },
      "source": [
        "##### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smyw6-a8L8A2",
        "outputId": "e928188a-539f-49cd-b80c-b70afa5ddb32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialisation of dynamic embedding... Done !\n",
            "Dynamic Embedding shape : Users [7047, 32], \t Items [97, 32]\n",
            "Number of users of 7047 \n",
            " Number of items 97 \n",
            "\n",
            "Dataset size [404702, 12]\n",
            "Initialisation of static embedding... Done !\n",
            "Static Embedding shape : Users [7047, 7047], \t Items [97, 97]\n",
            "Initialisation of rnn's with tanh activation function... Done !\n",
            "Initialisation of MLP... Done !\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 32\n",
        "data_torch = torch.from_numpy(data.values.astype(np.float32))\n",
        "U_dynamic,I_dynamic = dynamic_embedding(data_torch,embedding_dim)  # Initial dynamic embedding\n",
        "    \n",
        "U_dynamic = U_dynamic.to(device)\n",
        "I_dynamic = I_dynamic.to(device)\n",
        "\n",
        "model = RODIE(embedding_dim,data_torch,device=device,activation_rnn=\"tanh\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Its important to add this to the loss, because the dataset is unbalanced\n",
        "dropout_ratio = len(df_train['next_state_user'])/(1+np.sum(df_train['next_state_user']))\n",
        "weight_ratio = torch.Tensor([1,dropout_ratio]).to(device)\n",
        "print(weight_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUpwh4O8MZo_",
        "outputId": "c88e6232-ef76-40df-e024-05ed45f854f3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0000, 99.4843], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X09xB2eqL8A3"
      },
      "source": [
        "##### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test le modèle sur peu de données\n",
        "#import itertools\n",
        "#t_batches_ = dict(itertools.islice(t_batches.items(), 3000))"
      ],
      "metadata": {
        "id": "iGpg_gLLMwoo"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from  torch import nn\n",
        "from torch.nn import RNNCell\n",
        "from torch.nn.functional import one_hot\n",
        "import math\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "## This custom class of Linear, enables to initialize the weights of the layer to belong to a normal distribution ##\n",
        "\n",
        "class NormalLinear(nn.Linear):\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.normal_(0, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.normal_(0, stdv)\n",
        "\n",
        "## This function enables to create the dynamic embedding of each node ##\n",
        "def dynamic_embedding(data,embedding_dim):\n",
        "        num_users = len(torch.unique(data[:,0]))\n",
        "        num_items = len(torch.unique(data[:,1]))\n",
        "        dynamic_users_embedding = F.normalize(torch.randn(num_users,embedding_dim))\n",
        "        dynamic_items_embedding = F.normalize(torch.randn(num_items,embedding_dim))\n",
        "\n",
        "        print(\"Initialisation of dynamic embedding... Done !\")\n",
        "        print(\"Dynamic Embedding shape : Users {}, \\t Items {}\".format(list(dynamic_users_embedding.size()),list(dynamic_items_embedding.size())))\n",
        "\n",
        "        return dynamic_users_embedding,dynamic_items_embedding\n",
        "        \n",
        "\n",
        "class RODIE(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,embedding_dim,data,device,activation_rnn=\"relu\",MLP_h_dim=50,option=\"user_state\"):\n",
        "        super(RODIE, self).__init__()\n",
        "        self.option = option\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.activation_rnn = activation_rnn\n",
        "        self.data = data\n",
        "        self.MLP_h_dim = MLP_h_dim  # The dimension of the hidden layer of the MLP used for the classification of Users \n",
        "        # Select features of the data\n",
        "        self.features = self.data[:,8:]\n",
        "        self.dim_features = self.features.shape[1]\n",
        "        # Number of users and number of items\n",
        "        num_users = len(torch.unique(data[:,0]))\n",
        "\n",
        "        num_items = len(torch.unique(data[:,1]))\n",
        "\n",
        "\n",
        "        print(\"Number of users of {} \\n Number of items {} \\n\".format(num_users,num_items))\n",
        "        print(\"Dataset size {}\".format(list(self.data.size())))\n",
        "        # Initialize static  embeddings\n",
        "        self.static_users_embedding = one_hot(torch.arange(0,num_users))\n",
        "        self.static_items_embedding = one_hot(torch.arange(0,num_items))\n",
        "        static_user_embedding_dim = self.static_users_embedding.shape[1]\n",
        "        static_item_embedding_dim = self.static_items_embedding.shape[1]\n",
        "        print(\"Initialisation of static embedding... Done !\")\n",
        "        print(\"Static Embedding shape : Users {}, \\t Items {}\".format(list(self.static_users_embedding.size()),list(self.static_items_embedding.size())))\n",
        "\n",
        "        # Initialize dynamic  embeddings\n",
        "        # In JODIE official implementation, authors decided to attribute the SAME initial dynamic embedding \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        input_rnn_user_dim =  self.embedding_dim + self.dim_features + 1\n",
        "\n",
        "        input_rnn_item_dim =  self.embedding_dim + self.dim_features + 1\n",
        "\n",
        "        self.item_rnn = RNNCell(input_rnn_user_dim, self.embedding_dim, nonlinearity = self.activation_rnn)\n",
        "\n",
        "\n",
        "        self.user_rnn = RNNCell(input_rnn_item_dim,self.embedding_dim, nonlinearity = self.activation_rnn)\n",
        "\n",
        "        print(\"Initialisation of rnn's with {} activation function... Done !\".format(self.activation_rnn))\n",
        "\n",
        "        # Projection layer -> projection operation   \n",
        "        self.projection_layer = nn.Linear(1,self.embedding_dim, bias=False)\n",
        "        # Predict next item embedding layer\n",
        "        self.predictItem_layer = nn.Linear(static_item_embedding_dim + static_user_embedding_dim  + 2*self.embedding_dim, static_item_embedding_dim + self.embedding_dim, bias=True)\n",
        "\n",
        "        self.predictStateUser_MLP = torch.nn.Sequential(\n",
        "            nn.Linear(self.embedding_dim,self.MLP_h_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            nn.Linear(self.MLP_h_dim,2)\n",
        "            )\n",
        "        print(\"Initialisation of MLP... Done !\")\n",
        "\n",
        "\n",
        "    ######## Predicting next item embedding  ########\n",
        "    def update_item_rnn(self,\n",
        "                          dynamic_item_embedding, # at t-1\n",
        "                          dynamic_user_embedding,# at t-1\n",
        "                          features,\n",
        "                          delta_i,\n",
        "):\n",
        "\n",
        "      concat_input = torch.concat([\n",
        "                                  dynamic_user_embedding,\n",
        "                                  delta_i.reshape(-1,1),\n",
        "                                  features,\n",
        "      ],axis=1)\n",
        "                                 \n",
        "\n",
        "      \n",
        "      concat_input = F.normalize(concat_input)\n",
        "      dynamic_item_embedding = F.normalize(dynamic_item_embedding)  \n",
        "      return F.normalize(self.item_rnn(concat_input,dynamic_item_embedding))\n",
        "\n",
        "\n",
        "\n",
        "    ######## Predicting next user embedding  ########\n",
        "    def update_user_rnn(self,\n",
        "                        dynamic_user_embedding, # at t-1\n",
        "                        dynamic_item_embedding,# at t-1\n",
        "                        features,\n",
        "                        delta_u):\n",
        "      concat_input = torch.concat([\n",
        "                                  dynamic_item_embedding,\n",
        "                                  delta_u.reshape(-1,1),\n",
        "                                   features],\n",
        "                                  axis=1)\n",
        "      \n",
        "\n",
        "      concat_input = F.normalize(concat_input)\n",
        "      dynamic_user_embedding = F.normalize(dynamic_user_embedding)  \n",
        "\n",
        "\n",
        "      return F.normalize(self.user_rnn(concat_input,dynamic_user_embedding))\n",
        "\n",
        "    \n",
        "\n",
        "    ######## Projecting the embedding the new dynamic embedding of the user at a future time  ########\n",
        "    def projection_operation(self,\n",
        "                            dynamic_user_embedding,\n",
        "                            delta_u):\n",
        "        u_projection =  dynamic_user_embedding * (1 + self.projection_layer(delta_u.reshape(-1,1)))\n",
        "\n",
        "        return u_projection\n",
        "        \n",
        "    ######## Predicting next potential item, the specific user will interact with  ########\n",
        "    \n",
        "    def predict_item_embedding(self,\n",
        "        u_projection,\n",
        "        u_static,\n",
        "        i_dynamic,\n",
        "        i_static\n",
        "        ):\n",
        "        concatenated_input = torch.concat([u_projection,i_dynamic,i_static,u_static],axis=1)\n",
        "        j_tilde = self.predictItem_layer(concatenated_input)\n",
        "        return j_tilde\n",
        "\n",
        "    ######## Predicting next user state  ########\n",
        "\n",
        "    def predict_user_state(self,dynamic_user_embedding):\n",
        "        u_state = self.predictStateUser_MLP(dynamic_user_embedding)\n",
        "\n",
        "        return u_state\n",
        "\n",
        "    def forward(self,\n",
        "                actual_item_embedding,\n",
        "                actual_user_embedding,\n",
        "                u_static,\n",
        "                i_static,\n",
        "                f,\n",
        "                delta_u,\n",
        "                delta_i,\n",
        "                next_state_label,\n",
        "                next_item_dynamic_embedding,\n",
        "                next_item_static_embedding\n",
        "                ):\n",
        "      ######## New  Dynamic Embeddings ########\n",
        "      # New dynamic embedding of the user\n",
        "      future_user_embedding= self.update_user_rnn(actual_user_embedding,actual_item_embedding,f,delta_u)\n",
        "      # New dynamic embedding of the item\n",
        "      future_item_embedding= self.update_item_rnn(actual_item_embedding,actual_user_embedding,f,delta_i)     \n",
        "\n",
        "\n",
        "      # Projection of the user\n",
        "\n",
        "      projected_user_embedding = self.projection_operation(future_user_embedding,delta_u)\n",
        "\n",
        "      # Predict next item\n",
        "      j_tilde = self.predict_item_embedding(\n",
        "        projected_user_embedding,\n",
        "        u_static,\n",
        "        future_item_embedding,\n",
        "        i_static)\n",
        "      \n",
        "      # The real next item embedding j_true, is the concatenation of the static and dynamic embedding of the next item \n",
        "      j_true = torch.concat([next_item_dynamic_embedding,next_item_static_embedding],axis=1).detach()\n",
        "        # Prediction of next state of the user using an MLP at the end\n",
        "      U_pred_state = self.predict_user_state(future_user_embedding)\n",
        "\n",
        "      return future_user_embedding,future_item_embedding,U_pred_state,j_tilde,j_true\n"
      ],
      "metadata": {
        "id": "um68Ognoizmd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.nn import MSELoss, HuberLoss,L1Loss,CrossEntropyLoss\n",
        "from preprocessing import *\n",
        "import torch\n",
        "from  torch import nn\n",
        "from torch.nn import RNNCell\n",
        "from torch.nn.functional import one_hot\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from torch.nn import MSELoss, HuberLoss,L1Loss,CrossEntropyLoss\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def regularizer(actual_user_embedding,future_user_embedding,lambda_u,\n",
        "                               actual_item_embedding,future_item_embedding,lambda_i\n",
        "                               ):\n",
        "    u_regularization_loss =  MSELoss()(actual_user_embedding,future_user_embedding)\n",
        "    i_regularization_loss =  MSELoss()(actual_item_embedding,future_item_embedding)\n",
        "    return lambda_u* u_regularization_loss + lambda_i* i_regularization_loss \n",
        "\n",
        "\n",
        "def train_rodie(t_batches,\n",
        "          data,\n",
        "          U,\n",
        "          I,\n",
        "          weight_ratio,\n",
        "          model,\n",
        "          optimizer,\n",
        "          n_epochs,\n",
        "          lambda_u,\n",
        "          lambda_i,\n",
        "          device,\n",
        "\n",
        "          ):\n",
        "  print(\"Training...\")\n",
        " # U_copy = U.clone().detach()\n",
        " # I_copy = I.clone().detach()\n",
        "\n",
        "  for e in range(n_epochs):\n",
        "    l = 0\n",
        "    \n",
        "    for (_,rows),_ in zip(t_batches.items(),tqdm(range(len(t_batches)), position=0, leave=True)):\n",
        "      optimizer.zero_grad()\n",
        "      users_idx,items_idx = extractItemUserId(data,rows)\n",
        "\n",
        "      state_label,delta_u,delta_i,f = extractFeatures(data,rows)\n",
        "\n",
        "      next_state,next_item = extractNextStateItem(data,rows)\n",
        "\n",
        "      u_static, i_static = model.static_users_embedding[users_idx], model.static_items_embedding[items_idx]\n",
        "\n",
        "      user_embedding, item_embedding = U[users_idx], I[items_idx]\n",
        "      next_item_static_embedding, next_item_dynamic_embedding = model.static_items_embedding[[int(x) for x in next_item]], I[[int(x) for x in next_item]]\n",
        "\n",
        "     # next_state = next_state.type(torch.LongTensor).to(device)\n",
        "      item_embedding = item_embedding.to(device)\n",
        "      user_embedding  = user_embedding.to(device)\n",
        "      u_static = u_static.to(device)\n",
        "      i_static = i_static.to(device)\n",
        "      f = f.to(device)\n",
        "      delta_u = delta_u.to(device)\n",
        "      delta_i = delta_i.to(device)\n",
        "      next_state = next_state.type(torch.LongTensor).to(device)\n",
        "      next_item_dynamic_embedding = next_item_dynamic_embedding.to(device)\n",
        "      next_item_static_embedding = next_item_static_embedding.to(device)\n",
        "      \n",
        "      # The forward pass of the model : extract dynamic embeddings (user+item ), and predicted user state and predicted item embedding\n",
        "      future_user_embedding,future_item_embedding,U_pred_state,j_tilde,j_true  = model(item_embedding,\n",
        "                user_embedding,\n",
        "                u_static,\n",
        "                i_static,\n",
        "                f,\n",
        "                delta_u,\n",
        "                delta_i,\n",
        "                next_state,\n",
        "                next_item_dynamic_embedding,\n",
        "                next_item_static_embedding)\n",
        "      # Add the new embedding to the placeholder U and I\n",
        "      U[users_idx] = future_user_embedding.detach().clone()\n",
        "      I[items_idx] = future_item_embedding.detach().clone() \n",
        "      \n",
        "      # Return loss value between the predicted embedding \"j_tilde\" and the real next item embedding j_true\n",
        "      loss = MSELoss()(j_tilde,j_true)#.detach()\n",
        "      loss += regularizer(user_embedding,future_user_embedding,lambda_u,\n",
        "                            item_embedding,future_item_embedding,lambda_i\n",
        "                            )\n",
        "        \n",
        "      loss += CrossEntropyLoss(weight_ratio)(U_pred_state,next_state)\n",
        "\n",
        "      #print(I[0])\n",
        "      loss.backward()\n",
        "      l += loss.item()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.)\n",
        "      optimizer.step()\n",
        "    print(I[0])\n",
        "    print(\"Epoch {} Loss {}\".format(e,l))\n",
        "    #print(I[0])\n",
        "    #print(U[0])\n",
        "  return model,U,I\n"
      ],
      "metadata": {
        "id": "zt6E9Mmzitaj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zytz5La7L8A3",
        "outputId": "5ddadc00-b2ba-4e0a-9865-d4eb0be4bee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 33650/33651 [05:25<00:00, 103.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9.8860e-01,  5.5337e-02, -4.7108e-02, -4.5311e-05,  1.0243e-02,\n",
            "         5.6318e-02,  1.2318e-02,  1.0192e-03,  3.8686e-03, -5.5764e-03,\n",
            "        -1.5759e-02, -8.0964e-03,  7.6300e-03,  2.7499e-03, -3.6310e-02,\n",
            "         2.4301e-02, -8.0339e-03,  5.3727e-02, -2.8305e-02, -3.1376e-03,\n",
            "        -2.9317e-02, -2.1991e-02, -2.2163e-03,  1.9257e-02,  2.7269e-02,\n",
            "         6.5157e-02,  1.6053e-02, -2.8265e-02,  1.2832e-03,  3.3686e-03,\n",
            "         8.3686e-03, -4.3995e-03], device='cuda:0')\n",
            "Epoch 0 Loss 4401450.301294162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 33650/33651 [05:27<00:00, 102.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9.8644e-01, -1.4825e-03, -7.4219e-03, -2.6905e-02, -4.7341e-03,\n",
            "        -2.3056e-02,  5.5169e-02,  3.7053e-02,  1.8710e-02,  7.3854e-03,\n",
            "         5.4933e-02, -1.4141e-02, -4.0840e-02,  1.3960e-02,  1.9729e-02,\n",
            "         5.4289e-02,  4.9004e-02,  3.2589e-03, -4.5193e-02, -4.5946e-02,\n",
            "         3.1026e-02, -2.6330e-02, -2.0435e-02,  8.2604e-03,  1.5846e-02,\n",
            "         1.6439e-03,  8.8992e-04,  4.3858e-02,  1.7390e-02,  2.3897e-02,\n",
            "         1.8052e-03, -2.4710e-02], device='cuda:0')\n",
            "Epoch 1 Loss 11066.51004626276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 33650/33651 [05:20<00:00, 104.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9910, -0.0111,  0.0186,  0.0188, -0.0117, -0.0020,  0.0277, -0.0107,\n",
            "        -0.0534,  0.0280,  0.0097,  0.0122,  0.0030, -0.0149,  0.0066, -0.0190,\n",
            "         0.0482, -0.0160, -0.0398, -0.0512,  0.0057, -0.0153,  0.0131,  0.0141,\n",
            "        -0.0268, -0.0016,  0.0246,  0.0469, -0.0098,  0.0104,  0.0112,  0.0159],\n",
            "       device='cuda:0')\n",
            "Epoch 2 Loss 10766.419765417464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 10023/33651 [01:37<03:52, 101.71it/s]"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "lambda_u = 1e-3\n",
        "lambda_i = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)\n",
        "\n",
        "model_,U,I = train_rodie(t_batches_train,\n",
        "          data_torch,\n",
        "          U_dynamic,\n",
        "          I_dynamic,\n",
        "          weight_ratio,\n",
        "          model,\n",
        "          optimizer,\n",
        "          n_epochs,\n",
        "          lambda_u,\n",
        "          lambda_i,\n",
        "          device\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSNE"
      ],
      "metadata": {
        "id": "0TnL3bTCZp8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "for x,y in t_batches_train.items():\n",
        "  l.append(y)\n",
        "\n",
        "\n",
        "dd = sum(l, [])\n",
        "ff = data.iloc[dd,:].copy()\n",
        "list_of_change = ff[ff['next_state_user'] == 1]['user_id'].values\n",
        "\n",
        "\n",
        "data_  = (U.detach().cpu().clone()).numpy()\n",
        "\n",
        "list_of_change = ff[ff['next_state_user'] == 1]['user_id'].values\n",
        "\n",
        "df = pd.DataFrame(data_)\n",
        "df['label'] = np.zeros((7047,1))\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    for d in list_of_change:\n",
        "      if index == d:\n",
        "        df.iloc[index,-1] = 1\n",
        "\n",
        "\n",
        "tsne =TSNE(2)\n",
        "\n",
        "data_tsne = tsne.fit_transform(data_)\n",
        "\n",
        "\n",
        "plt.scatter(data_tsne[:,0],data_tsne[:,1],c=df['label'])"
      ],
      "metadata": {
        "id": "r4M2czlFPd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G3L9vyoQcu7I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "bef1584e9c6af06ba1c2e66d205bd6622ae056162fc057ef1acd3cc06b90e6ba"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}