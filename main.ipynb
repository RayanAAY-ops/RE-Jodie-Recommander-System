{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xq_u5mj7L8Av"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from preprocessing import extract_data_mooc, extractFeatures,extractItemUserId,extractNextStateItem,extractNextUserState,UserNextInteraction, delta, t_batch_update\n",
        "from model import RODIE,dynamic_embedding\n",
        "from train import train_rodie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2fs_9WWL8Ax",
        "outputId": "26b0d457-ae3f-4d1d-8863-1e5f930095ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-17 09:23:14--  https://snap.stanford.edu/data/act-mooc.tar.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5378133 (5.1M) [application/x-gzip]\n",
            "Saving to: ‘act-mooc.tar.gz’\n",
            "\n",
            "act-mooc.tar.gz     100%[===================>]   5.13M  8.27MB/s    in 0.6s    \n",
            "\n",
            "2022-03-17 09:23:15 (8.27 MB/s) - ‘act-mooc.tar.gz’ saved [5378133/5378133]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Téléchargement des données\n",
        "!wget https://snap.stanford.edu/data/act-mooc.tar.gz\n",
        "!tar -xzf  act-mooc.tar.gz\n",
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4T5CbB9KL8Ax"
      },
      "outputs": [],
      "source": [
        "features = pd.read_csv(\"act-mooc/mooc_action_features.tsv\",sep=\"\\t\")\n",
        "labels = pd.read_csv(\"act-mooc/mooc_action_labels.tsv\",sep=\"\\t\")\n",
        "users = pd.read_csv(\"act-mooc/mooc_actions.tsv\",sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLCAaTlZL8Ay"
      },
      "source": [
        "#### Load & Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFoGBgxNL8Az"
      },
      "outputs": [],
      "source": [
        "mooc_data = extract_data_mooc()\n",
        "\n",
        "delta_u  = delta(mooc_data.copy(),\"user_id\")\n",
        "delta_i  = delta(mooc_data.copy(),\"item_id\")\n",
        "nextItemInteraction = UserNextInteraction(mooc_data.copy())\n",
        "next_state_user = extractNextUserState(mooc_data.copy())\n",
        "\n",
        "\n",
        "mooc_data['delta_u'] = delta_u\n",
        "mooc_data['delta_i'] = delta_i\n",
        "mooc_data['nextItemInteraction'] = nextItemInteraction\n",
        "mooc_data['next_state_user'] = next_state_user\n",
        "\n",
        "data = mooc_data.copy()\n",
        "data = data[ (data.nextItemInteraction != -1) | (data.next_state_user != -1)  ]\n",
        "\n",
        "data = data[['user_id', 'item_id', 'timestamp', 'state_label','delta_u', 'delta_i', 'nextItemInteraction', 'next_state_user','f1', 'f2', 'f3','f4']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiCCdNMNL8A0"
      },
      "source": [
        "#### T-batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwkh7WDqL8A1",
        "outputId": "8d8ea03f-655e-4049-e614-fdbbec8315d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-Batch start...\n",
            "Number of interaction = 404702\n",
            "T-Batch ends !\n"
          ]
        }
      ],
      "source": [
        "t_batches = t_batch_update(data.reset_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZldOSzFL8A1"
      },
      "source": [
        "##### Initialize Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xuMzz5NL8A1",
        "outputId": "f8a4a9bf-b21f-49f4-9804-f4dcd5a97506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = \"cpu\"\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyoLG1SXL8A2"
      },
      "source": [
        "##### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smyw6-a8L8A2",
        "outputId": "eb01b0d1-8507-415b-9c2c-f3fa13b9aa7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialisation of dynamic embedding... Done !\n",
            "Dynamic Embedding shape : Users [7047, 32], \t Items [97, 32]\n",
            "Number of users of 7047 \n",
            " Number of items 97 \n",
            "\n",
            "Dataset size [404702, 12]\n",
            "Initialisation of static embedding... Done !\n",
            "Static Embedding shape : Users [7047, 7047], \t Items [97, 97]\n",
            "Initialisation of rnn's with relu activation function... Done !\n",
            "Initialisation of MLP... Done !\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 32\n",
        "data_torch = torch.from_numpy(data.values.astype(np.float32))\n",
        "U_dynamic,I_dynamic = dynamic_embedding(data_torch,embedding_dim)  # Initial dynamic embedding\n",
        "    \n",
        "U_dynamic = U_dynamic.to(device)\n",
        "I_dynamic = I_dynamic.to(device)\n",
        "\n",
        "model = RODIE(embedding_dim,data_torch,device=device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Its important to add this to the loss, because the dataset is unbalanced\n",
        "dropout_ratio = len(data['state_label'])/(1+np.sum(data['state_label']))\n",
        "weight_ratio = torch.Tensor([1,dropout_ratio]).to(device)"
      ],
      "metadata": {
        "id": "GUpwh4O8MZo_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X09xB2eqL8A3"
      },
      "source": [
        "##### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test le modèle sur peu de données\n",
        "import itertools\n",
        "t_batches_ = dict(itertools.islice(t_batches.items(), 3000))"
      ],
      "metadata": {
        "id": "iGpg_gLLMwoo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.nn import MSELoss, HuberLoss,L1Loss,CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from  torch import nn\n",
        "from torch.nn import RNNCell\n",
        "from torch.nn.functional import one_hot\n",
        "import math\n",
        "from torch.nn import MSELoss, HuberLoss,L1Loss,CrossEntropyLoss\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def regularizer(actual_user_embedding,future_user_embedding,lambda_u,\n",
        "                               actual_item_embedding,future_item_embedding,lambda_i\n",
        "                               ):\n",
        "    u_regularization_loss =  MSELoss()(actual_user_embedding,future_user_embedding)\n",
        "    i_regularization_loss =  MSELoss()(actual_item_embedding,future_item_embedding)\n",
        "    return lambda_u* u_regularization_loss + lambda_i* i_regularization_loss \n",
        "\n",
        "\n",
        "def train_rodie(t_batches,\n",
        "          data,\n",
        "          U,\n",
        "          I,\n",
        "          weight_ratio,\n",
        "          model,\n",
        "          optimizer,\n",
        "          n_epochs,\n",
        "          lambda_u,\n",
        "          lambda_i,\n",
        "          device,\n",
        "\n",
        "          ):\n",
        "  print(\"Training...\")\n",
        " # U_copy = U.clone().detach()\n",
        " # I_copy = I.clone().detach()\n",
        "\n",
        "  for e in range(n_epochs):\n",
        "    l = 0\n",
        "    \n",
        "    for (_,rows),_ in zip(t_batches.items(),tqdm(range(len(t_batches)), position=0, leave=True)):\n",
        "      optimizer.zero_grad()\n",
        "      users_idx,items_idx = extractItemUserId(data,rows)\n",
        "\n",
        "      state_label,delta_u,delta_i,f = extractFeatures(data,rows)\n",
        "\n",
        "      next_state,next_item = extractNextStateItem(data,rows)\n",
        "\n",
        "      u_static, i_static = model.static_users_embedding[users_idx], model.static_items_embedding[items_idx]\n",
        "\n",
        "      user_embedding, item_embedding = U[users_idx], I[items_idx]\n",
        "      next_item_static_embedding, next_item_dynamic_embedding = model.static_items_embedding[[int(x) for x in next_item]], I[[int(x) for x in next_item]]\n",
        "\n",
        "     # next_state = next_state.type(torch.LongTensor).to(device)\n",
        "      item_embedding = item_embedding.to(device)\n",
        "      user_embedding  = user_embedding.to(device)\n",
        "      u_static = u_static.to(device)\n",
        "      i_static = i_static.to(device)\n",
        "      f = f.to(device)\n",
        "      delta_u = delta_u.to(device)\n",
        "      delta_i = delta_i.to(device)\n",
        "      next_state = next_state.type(torch.LongTensor).to(device)\n",
        "      next_item_dynamic_embedding = next_item_dynamic_embedding.to(device)\n",
        "      next_item_static_embedding = next_item_static_embedding.to(device)\n",
        "\n",
        "      \n",
        "      future_user_embedding,future_item_embedding,U_pred_state,j_tilde,j_true  = model(item_embedding,\n",
        "                user_embedding,\n",
        "                u_static,\n",
        "                i_static,\n",
        "                f,\n",
        "                delta_u,\n",
        "                delta_i,\n",
        "                next_state,\n",
        "                next_item_dynamic_embedding,\n",
        "                next_item_static_embedding) \n",
        "      U[users_idx] = future_user_embedding.detach().clone()\n",
        "      I[items_idx] = future_item_embedding.detach().clone()     \n",
        "      # Return loss value between the predicted embedding \"j_tilde\" and the real next item embedding j_true\n",
        "      loss = MSELoss()(j_tilde,j_true)\n",
        "      loss += regularizer(user_embedding,future_user_embedding,lambda_u,\n",
        "                            item_embedding,future_item_embedding,lambda_i\n",
        "                            )\n",
        "        \n",
        "      loss += CrossEntropyLoss(weight_ratio)(U_pred_state,next_state)\n",
        "\n",
        "      #print(I[0])\n",
        "      loss.backward()\n",
        "      l += loss.item()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.)\n",
        "      optimizer.step()\n",
        "    print(I[0])\n",
        "    print(\"Epoch {} Loss {}\".format(e,l))\n",
        "    #print(I[0])\n",
        "    #print(U[0])\n",
        "  return model,U,I"
      ],
      "metadata": {
        "id": "7UcgKNRgNBiE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zytz5La7L8A3"
      },
      "outputs": [],
      "source": [
        "n_epochs = 3\n",
        "lambda_u = 1e-3\n",
        "lambda_i = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)\n",
        "\n",
        "model_,U,I = train_rodie(t_batches_,\n",
        "          data_torch,\n",
        "          U_dynamic,\n",
        "          I_dynamic,\n",
        "          weight_ratio,\n",
        "          model,\n",
        "          optimizer,\n",
        "          n_epochs,\n",
        "          lambda_u,\n",
        "          lambda_i,\n",
        "          device\n",
        "          )"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "bef1584e9c6af06ba1c2e66d205bd6622ae056162fc057ef1acd3cc06b90e6ba"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}